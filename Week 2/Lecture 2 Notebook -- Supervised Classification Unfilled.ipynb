{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76414478",
   "metadata": {},
   "source": [
    "# Turing Machine & Deep Learning 2023\n",
    "*Author: Satchit Chatterji (satchit.chatterji@gmail.com)*\n",
    "\n",
    "## Lecture 2: Supervised ML (Classification)\n",
    "> Today's question: How can I classify handwritten digits?\n",
    "\n",
    "The MNIST dataset is a widely used benchmark dataset in machine learning and computer vision. It consists of a collection of 70,000 grayscale images of handwritten digits from 0 to 9. Each image is a 28x28 pixel square, making it a 28x28 matrix of numerical values. The MNIST dataset is often used for tasks such as digit recognition and serves as a fundamental dataset for developing and evaluating various image classification algorithms and models.\n",
    "\n",
    "Today, we'll try to classify digits in this dataset using methods we learnt in the lecture.\n",
    "\n",
    "#### Learning outcomes:\n",
    "- Using benchmark data sets (MNIST)\n",
    "- Reshaping inputs, outputs\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b4e64",
   "metadata": {},
   "source": [
    "# Loading MNIST\n",
    "\n",
    "Because it is so popular, we can get an easily-accessible version via e.g. [TensorFlow](https://www.tensorflow.org/) that already comes with a test/train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# get common libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc984c62",
   "metadata": {},
   "source": [
    "## Exploring MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a2ac1",
   "metadata": {},
   "source": [
    "### Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85804915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(...)\n",
    "plt.xticks(0.9*np.arange(10)+0.45, range(10))\n",
    "\n",
    "plt.ylabel(...)\n",
    "plt.xlabel(...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977a53b",
   "metadata": {},
   "source": [
    "### Exploring the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e11fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e03e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bunch more images\n",
    "\n",
    "fig, axs = plt.subplots(5,5)\n",
    "axs = axs.flatten()\n",
    "fig.tight_layout(pad=0.3)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(...)\n",
    "    ax.set_title(...)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754193b9",
   "metadata": {},
   "source": [
    "### Reshaping MNIST\n",
    "\n",
    "The ML algorithms used in this notebook usually expect the input to be a vector, and not a matrix. Thus, we need to reshape the samples into a single vector that is 784 dimensions long.\n",
    "\n",
    "Later on, we will also need to reshape these back into single images, so we add a function for that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabfc00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def flatten_mnist(samples):\n",
    "    return ...\n",
    "\n",
    "def unflatten_mnist(image):\n",
    "    return ...\n",
    "\n",
    "train_X, test_X = flatten_mnist(train_X), flatten_mnist(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e0ba6",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "... # create the logistic regression object\n",
    "... # fit on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f55336",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fde720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import seaborn as sns\n",
    "\n",
    "# compute cm and plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a17a81",
   "metadata": {},
   "source": [
    "The raw confusion matrix for such an accurate baseline model doesn't seem to be too helpful. Instead, we can get the metrics computed directly for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c32ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a function from sklearn for a full classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# make predictions\n",
    "...\n",
    "# send to classification_report\n",
    "print(\"Logistic Regression\")\n",
    "print(classification_report(test_y, pred_y, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56428ad",
   "metadata": {},
   "source": [
    "For now, and what is common for balanced datasets, is to use accuracies as a good inital metric to see how your model is doing. So let's just compute them directly and display them for both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute score for a single dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(...):\n",
    "    print(\"Training score:\", ...)\n",
    "    print(\"Testing score: \", ...)\n",
    "    \n",
    "get_accuracies(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_incorrect_preds(pred_y, test_X, test_y):\n",
    "    incorrect_idxs = pred_y!=test_y\n",
    "\n",
    "    incorrect_pred_y = pred_y[incorrect_idxs]\n",
    "    incorrect_test_X = test_X[incorrect_idxs]\n",
    "    incorrect_test_y = test_y[incorrect_idxs]\n",
    "\n",
    "    fig, axs = plt.subplots(5,5)\n",
    "    axs = axs.flatten()\n",
    "    fig.tight_layout(pad=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.imshow(unflatten_mnist(incorrect_test_X[i]), cmap=plt.get_cmap('gray'))\n",
    "        ax.set_title(fr\"{incorrect_pred_y[i]}$\\neq${incorrect_test_y[i]}\")\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "show_incorrect_preds(pred_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04d9d3",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ea47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "modelDT = tree.DecisionTreeClassifier(...)\n",
    "modelDT = modelDT.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree\")\n",
    "get_accuracies(..., train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = modelDT.predict(...)\n",
    "show_incorrect_preds(pred_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf06c0",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "modelRFC = RFC(...)\n",
    "modelRFC = modelRFC.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\n",
    "get_accuracies(modelRFC, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = modelRFC.predict(test_X)\n",
    "show_incorrect_preds(pred_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0a5d8",
   "metadata": {},
   "source": [
    "# SVMs\n",
    "\n",
    "SVMs come in a number of flavors with a number of hyperparameters you can play around with. Try them all out here! Keep in mind that since we have so many high-dimensional data points, this method can be excruitiatingly slow.\n",
    "\n",
    "Let's run these cells first before going back to the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9841a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVC = SVC(kernel=\"rbf\", C=10, gamma=0.01)\n",
    "modelSVC = modelSVC.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "get_accuracies(modelSVC, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = modelSVC.predict(test_X)\n",
    "show_incorrect_preds(pred_y, test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
