{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yW_3DjlSruH"
   },
   "source": [
    "# Turing Machine and Deep Learning 2023\n",
    "_Author: Satchit Chatterji (satchit.chatterji@gmail.com)_\n",
    "\n",
    "## Lecture 3 -- Unsupervised Learning methods\n",
    "> Today's question: **How do I understand unlabelled data points?**\n",
    "\n",
    "This notebook is a guide into the most common and arguably most useful unsupervised learning algorithms.\n",
    "\n",
    "*Note: More on K-Means can be found in the notebook from [Python for Data Science 2022](https://github.com/satchitchatterji/PythonForDataScience/blob/main/lecture4/Tangent_K_means_clustering.ipynb).*\n",
    "\n",
    "#### Notebook outline:\n",
    "- Dataset MNIST\n",
    "- PCA decomposition\n",
    "- K-Means clustering\n",
    "- Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important libraries and dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset: we saw this last week too!\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# import PCA decomposition class from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Data preprocessing\n",
    "# Reshape and normalize the data\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "\n",
    "# Step 2,3,4\n",
    "# Set up PCA object\n",
    "pca = PCA(n_components=2)  # Set the desired number of components\n",
    "# perform covariance matrix computation\n",
    "# and eigendecomposition\n",
    "x_train_pca = pca.fit(x_train)\n",
    "\n",
    "# Step 5: Project data to lower dimension\n",
    "x_train_pca = pca.transform(x_train)\n",
    "\n",
    "# Note: you can also fit and transform in one function: pca.fit_transform\n",
    "\n",
    "# Plotting the projected data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=y_train, cmap='tab10', alpha=0.6, s=1)\n",
    "plt.colorbar()\n",
    "plt.title('MNIST Data Projected using PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KMeans class\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select a random subset of the dataset\n",
    "random_subset = np.random.choice(len(x_train), size=2000, replace=False)\n",
    "x_subset = x_train[random_subset]\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(x_subset)\n",
    "\n",
    "# Randomly select a data point\n",
    "random_index = np.random.randint(len(x_subset))\n",
    "random_data_point = x_subset[random_index]\n",
    "\n",
    "# Predict the cluster for the selected data point\n",
    "predicted_cluster = kmeans.predict([random_data_point])\n",
    "\n",
    "# Get the cluster center for the predicted cluster\n",
    "predicted_center = kmeans.cluster_centers_[predicted_cluster]\n",
    "\n",
    "# get the closest training point to the predicted center\n",
    "closest_point_to_pred = np.argmin(kmeans.transform(x_subset)[:,predicted_cluster])\n",
    "\n",
    "# Reshape the data point and the cluster center for visualization\n",
    "random_data_point_img = random_data_point.reshape(28, 28)\n",
    "predicted_center_img = predicted_center.reshape(28, 28)\n",
    "closest_pred_img = x_subset[closest_point_to_pred].reshape(28, 28)\n",
    "\n",
    "# Plot images\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(random_data_point_img, cmap='gray')\n",
    "plt.title('Random Data Point')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_center_img, cmap='gray')\n",
    "plt.title('Predicted Centroid')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(closest_pred_img, cmap='gray')\n",
    "plt.title('Closest to Centroid')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, center in enumerate(kmeans.cluster_centers_):\n",
    "    axs[i].imshow(center.reshape(28,28),cmap=\"gray\")\n",
    "    axs[i].axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the usefulness of the elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering for different values of K\n",
    "wcss = []\n",
    "k_values = range(1, 20)\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(x_subset)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(k_values, wcss, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GMM class\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Select a random subset of the dataset\n",
    "random_subset = np.random.choice(len(x_train), size=2000, replace=False)\n",
    "x_subset = x_train[random_subset]\n",
    "\n",
    "# Perform K-means clustering\n",
    "gmm = GaussianMixture(10)\n",
    "gmm.fit(x_subset)\n",
    "\n",
    "# Randomly select a data point\n",
    "random_index = np.random.randint(len(x_subset))\n",
    "random_data_point = x_subset[random_index]\n",
    "\n",
    "# Predict the cluster for the selected data point\n",
    "predicted_cluster = gmm.predict([random_data_point])\n",
    "\n",
    "# Get the cluster center for the predicted cluster\n",
    "predicted_center = gmm.means_[predicted_cluster]\n",
    "\n",
    "# get the closest training point to the predicted center\n",
    "closest_point_to_pred = np.argmax(gmm.predict_proba(x_subset)[:,predicted_cluster])\n",
    "\n",
    "# Reshape the data point and the cluster center for visualization\n",
    "random_data_point_img = random_data_point.reshape(28, 28)\n",
    "predicted_center_img = predicted_center.reshape(28, 28)\n",
    "closest_pred_img = x_subset[closest_point_to_pred].reshape(28, 28)\n",
    "\n",
    "# Plot images\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(random_data_point_img, cmap='gray')\n",
    "plt.title('Random Data Point')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_center_img, cmap='gray')\n",
    "plt.title('Predicted Centroid')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(closest_pred_img, cmap='gray')\n",
    "plt.title('Closest to Centroid')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, center in enumerate(gmm.means_):\n",
    "    axs[i].imshow(center.reshape(28,28),cmap=\"gray\")\n",
    "    axs[i].axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative models: A quick look\n",
    "\n",
    "An explicit generative model models the PDF of the data directly. Sampling from these distributions will give us new, generated examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random class from the training set\n",
    "random_class = np.random.randint(0, 10)\n",
    "print(\"Generating random samples of class\", random_class)\n",
    "\n",
    "# Filter the training set for samples of the random class\n",
    "class_samples = x_train[y_train == random_class]\n",
    "# class_samples = x_train[:1000]\n",
    "\n",
    "# Create a Gaussian Mixture Model with 10 components\n",
    "gmm = GaussianMixture(n_components=10, random_state=42)\n",
    "\n",
    "# Fit the GMM to the class samples\n",
    "gmm.fit(class_samples)\n",
    "\n",
    "# Generate new samples from the fitted GMM\n",
    "generated_samples = gmm.sample(10)[0]\n",
    "\n",
    "# Reshape the generated samples for visualization\n",
    "generated_samples_imgs = generated_samples.reshape(-1, 28, 28)\n",
    "\n",
    "# Plot the generated samples\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(len(generated_samples)):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(generated_samples_imgs[i], cmap='gray')\n",
    "    plt.title('Generated Sample {}'.format(i+1))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
